{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification using Simple Transformers (RoBERTa)\n",
    "\n",
    "\n",
    "## Problem statementÂ¶\n",
    "The goal of this project is to predict whether a comment is sarcastic or not based on 1 million comments scrapped from Reddit - also called sub-reddits. This means, we are facing a binary classification problem that involves incorporating NLP techniques to feed to our ML/DL models.\n",
    "\n",
    "## Goal of this notebook\n",
    "Our goal is to build a model to predict the comment's label (sarcastic or not). In this notebook, we will use some of the most popular state-of-the-art algorithms to classify text - RoBERTa. It stands for Robustly Optimized BERT Pre-training Approach. It was presented by researchers at Facebook and Washington Universityand their goals was to optimize the training of BERT architecture in order to take lesser time during pre-training. Moreover, we will be using simpletransformers library with the objective of making the implementation as simple as possible.\n",
    "\n",
    "## Important note: Training and predicting time\n",
    "Due to the size of our dataset, it may take a very long time to train the model and predict the labels!\n",
    "\n",
    "\n",
    "## Structure of this notebook\n",
    "0. Set-up and data cleansing\n",
    "1. Create datasets \n",
    "2. Modelling\n",
    "3. Evaluation\n",
    "4. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################\n",
    "###\n",
    "### Install all the necessary packages \n",
    "###\n",
    "###################################################################################################\n",
    "\n",
    "!pip install -r requirements_roberta.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "###\n",
    "### Import all the necessary packages and custom functions (from the functions.py file)\n",
    "###\n",
    "###################################################################################################\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "import pandas as pd\n",
    "import logging\n",
    "import sklearn\n",
    "import time\n",
    "\n",
    "from functions import *\n",
    "\n",
    "import torch\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "###\n",
    "### Get the data from the Google Drive public folders\n",
    "###\n",
    "###################################################################################################\n",
    "\n",
    "# Load train and test dataframes\n",
    "test_df = get_sarcasm_test_df()\n",
    "train_df = get_sarcasm_train_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create datasets\n",
    "In this case, based on the reduced amount of text characters in the comments, we will keep all the text without cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>\"\"I like my shortstops how I like my beef... i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>He works in mysterious ways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>You're right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Is this amount of meat in the ratio of meat to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>You can hug and kiss my ass X and O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  labels                                               text\n",
       "0   1       0  \"\"I like my shortstops how I like my beef... i...\n",
       "1   2       1                        He works in mysterious ways\n",
       "2   3       0                                       You're right\n",
       "3   4       0  Is this amount of meat in the ratio of meat to...\n",
       "4   5       0                You can hug and kiss my ass X and O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################################################################\n",
    "###\n",
    "### Prepare the datasets for the model\n",
    "###\n",
    "###################################################################################################\n",
    "\n",
    "# Initiate\n",
    "start_time = time.time()\n",
    "\n",
    "# Keep only the necessary columns\n",
    "test_df = test_df[['id', 'label', 'comment']].dropna()\n",
    "train_df = train_df[['id', 'label', 'comment']].dropna()\n",
    "\n",
    "# Change column names and cast data type to the text field as string\n",
    "test_df = test_df.rename(columns={\"comment\": \"text\", \"label\":\"labels\"})\n",
    "test_df['text'] = test_df['text'].astype('str')\n",
    "\n",
    "train_df = train_df.rename(columns={\"comment\": \"text\", \"label\":\"labels\"})\n",
    "train_df['text'] = train_df['text'].astype('str')\n",
    "\n",
    "# Show how does the dataframe look like\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modelling\n",
    "In this case, we will use 'comment' as the text input field for the model. We will use the simpletransformers library in order to make the pipeline easier to handle and prototype with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>\"\"I like my shortstops how I like my beef... i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>He works in mysterious ways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>You're right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Is this amount of meat in the ratio of meat to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>You can hug and kiss my ass X and O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  labels                                               text\n",
       "0   1       0  \"\"I like my shortstops how I like my beef... i...\n",
       "1   2       1                        He works in mysterious ways\n",
       "2   3       0                                       You're right\n",
       "3   4       0  Is this amount of meat in the ratio of meat to...\n",
       "4   5       0                You can hug and kiss my ass X and O"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################################################################\n",
    "###\n",
    "### Prepare the datasets for the model\n",
    "###\n",
    "###################################################################################################\n",
    "\n",
    "# Due to the size of our dataset and our limited hardware, let's reduce the size of the training and test datasets\n",
    "#   so we can run the model. We will keep a 70:30 ratio on the data between train and test datasets\n",
    "\n",
    "train_df_model = train_df[:210000]\n",
    "test_df_model = test_df[:90000]\n",
    "\n",
    "# Show how does the dataframe look like\n",
    "train_df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################\n",
    "###\n",
    "### Set up and initiate RoBERTa classification model\n",
    "###\n",
    "###################################################################################################\n",
    "\n",
    "# Log Results\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Set up simpletransformers classification model - we will select RoBERTa and the necessary arguments\n",
    "model = ClassificationModel('roberta', 'roberta-base', use_cuda=False, args={'reprocess_input_data': True, 'overwrite_output_dir': True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709c9e88f6174a64932099e0daf88192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_roberta_128_2_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ae3f9198254c92b42bac2bda8f4019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eed1efc474d410f9c6f8fde5cfc5955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 1:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61dd3edbba7f40f6b69c064cb2c05879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_roberta_128_2_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8683ca06c7e047c18671131d8e97363c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/analyticsserver/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'tp': 0, 'tn': 12, 'fp': 0, 'fn': 8, 'auroc': 0.8958333333333334, 'auprc': 0.8385912698412699, 'acc': 0.6, 'eval_loss': 0.6823578874270121}\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924ff01a865440eaa5c8059c33fecabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e96a5f1bf5476aa59a28f8553c5474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################################################################################################\n",
    "###\n",
    "### Train our model and predict over the test dataset\n",
    "###\n",
    "###################################################################################################\n",
    "\n",
    "# Train the train dataset with RoBERTa\n",
    "model.train_model(train_df_model)\n",
    "\n",
    "# Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(train_df_model, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "# Predict labels (is the comment sarcastic or not) on the test dataset\n",
    "predictions_values = model.predict(test_df_model['text'].to_numpy().tolist())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa classification model predicts correctly 50.00 percent of the Reddit comments\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################\n",
    "###\n",
    "### Evaluate the results\n",
    "###\n",
    "################################################################################################### \n",
    "\n",
    "\n",
    "# Inidicate when it finishes\n",
    "end_time = time.time()\n",
    "\n",
    "# Check the accuracy of the model\n",
    "accuracy_score(test_df_model.labels, predictions_values)\n",
    "print(\"RoBERTa classification model predicts correctly %.2f percent of the Reddit comments\"%(accuracy_score(test_df_model.labels, predictions_values)*100))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(test_df_model.labels, predictions_values, ['genuine','sarcastic'], figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Execution_Time_Seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roberta_comment_only_without_cleaning</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model  Accuracy  Execution_Time_Seconds\n",
       "0  roberta_comment_only_without_cleaning       0.5                    24.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################################################################\n",
    "###\n",
    "### Store the results\n",
    "###\n",
    "###################################################################################################\n",
    "\n",
    "# Store the final results from the RoBERTa model without cleaning\n",
    "roberta_results = pd.DataFrame({'id': test_df_model.id, 'predicted': predictions_values})\n",
    "roberta_results.to_csv(\"roberta_results.csv\")\n",
    "\n",
    "# Store the results for comparison\n",
    "score = round(accuracy_score(test_df_model.labels, predictions_values),2)\n",
    "model_name = 'roberta_comment_only_without_cleaning'\n",
    "\n",
    "# Create a table with the final results and print the results\n",
    "roberta_results_table = pd.DataFrame([[model_name, score, round(end_time - start_time,0)]], columns = ['Model', 'Accuracy', 'Execution_Time_Seconds'])\n",
    "roberta_results_table.to_csv(\"roberta_results_table.csv\")\n",
    "roberta_results_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
