{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification using Simple Transformers (RoBERTa)\n",
    "\n",
    "\n",
    "## Problem statementÂ¶\n",
    "The goal of this project is to predict whether a comment is sarcastic or not based on 1 million comments scrapped from Reddit - also called sub-reddits. This means, we are facing a binary classification problem that involves incorporating NLP techniques to feed to our ML/DL models.\n",
    "\n",
    "## Goal of this notebook\n",
    "Our goal is to build a model to predict the comment's label (sarcastic or not). In this notebook, we will use some of the most popular state-of-the-art algorithms to classify text - RoBERTa. It stands for Robustly Optimized BERT Pre-training Approach. It was presented by researchers at Facebook and Washington Universityand their goals was to optimize the training of BERT architecture in order to take lesser time during pre-training. Moreover, we will be using simpletransformers library with the objective of making the implementation as simple as possible.\n",
    "\n",
    "## Important note: Training and predicting time\n",
    "Due to the size of our dataset, it may take a very long time to train the model and predict the labels!\n",
    "\n",
    "\n",
    "## Structure of this notebook\n",
    "0. Set-up and data cleansing\n",
    "1. Create datasets \n",
    "2. Modelling\n",
    "3. Evaluation\n",
    "4. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "###\n",
    "### Install all the necessary packages \n",
    "###\n",
    "###################################################################################################\n",
    "\n",
    "!pip install -r requirements_roberta.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "###\n",
    "### Import all the necessary packages and custom functions (from the functions.py file)\n",
    "###\n",
    "###################################################################################################\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "import pandas as pd\n",
    "import logging\n",
    "import sklearn\n",
    "import time\n",
    "\n",
    "from functions import *\n",
    "\n",
    "import torch\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "###\n",
    "### Get the data from the Google Drive public folders\n",
    "###\n",
    "###################################################################################################\n",
    "\n",
    "# Load train and test dataframes\n",
    "test_df = get_sarcasm_test_df()\n",
    "train_df = get_sarcasm_train_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create datasets\n",
    "In this case, based on the reduced amount of text characters in the comments, we will keep all the text without cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "###\n",
    "### Prepare the datasets for the model\n",
    "###\n",
    "###################################################################################################\n",
    "\n",
    "# Initiate\n",
    "start_time = time.time()\n",
    "\n",
    "# Keep only the necessary columns\n",
    "test_df = test_df[['id', 'label', 'comment']].dropna()\n",
    "train_df = train_df[['id', 'label', 'comment']].dropna()\n",
    "\n",
    "# Change column names and cast data type to the text field as string\n",
    "test_df = test_df.rename(columns={\"comment\": \"text\", \"label\":\"labels\"})\n",
    "test_df['text'] = test_df['text'].astype('str')\n",
    "\n",
    "train_df = train_df.rename(columns={\"comment\": \"text\", \"label\":\"labels\"})\n",
    "train_df['text'] = train_df['text'].astype('str')\n",
    "\n",
    "# Show how does the dataframe look like\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modelling\n",
    "In this case, we will use 'comment' as the text input field for the model. We will use the simpletransformers library in order to make the pipeline easier to handle and prototype with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "###\n",
    "### Prepare the datasets for the model\n",
    "###\n",
    "###################################################################################################\n",
    "\n",
    "# Due to the size of our dataset and our limited hardware, let's reduce the size of the training and test datasets\n",
    "#   so we can run the model. We will keep a 70:30 ratio on the data between train and test datasets\n",
    "\n",
    "train_df_model = train_df[:210000]\n",
    "test_df_model = test_df[:90000]\n",
    "\n",
    "# Show how does the dataframe look like\n",
    "train_df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "###\n",
    "### Set up and initiate RoBERTa classification model\n",
    "###\n",
    "###################################################################################################\n",
    "\n",
    "# Log Results\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Set up simpletransformers classification model - we will select RoBERTa and the necessary arguments\n",
    "model = ClassificationModel('roberta', 'roberta-base', use_cuda=False, args={'reprocess_input_data': True, 'overwrite_output_dir': True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "###\n",
    "### Train our model and predict over the test dataset\n",
    "###\n",
    "###################################################################################################\n",
    "\n",
    "# Train the train dataset with RoBERTa\n",
    "model.train_model(train_df_model)\n",
    "\n",
    "# Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(train_df_model, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "# Predict labels (is the comment sarcastic or not) on the test dataset\n",
    "predictions_values = model.predict(test_df_model['text'].to_numpy().tolist())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "###\n",
    "### Evaluate the results\n",
    "###\n",
    "################################################################################################### \n",
    "\n",
    "\n",
    "# Inidicate when it finishes\n",
    "end_time = time.time()\n",
    "\n",
    "# Check the accuracy of the model\n",
    "accuracy_score(test_df_model.labels, predictions_values)\n",
    "print(\"RoBERTa classification model predicts correctly %.2f percent of the Reddit comments\"%(accuracy_score(test_df_model.labels, predictions_values)*100))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(test_df_model.labels, predictions_values, ['genuine','sarcastic'], figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "###\n",
    "### Store the results\n",
    "###\n",
    "###################################################################################################\n",
    "\n",
    "# Store the final results from the RoBERTa model without cleaning\n",
    "roberta_results = pd.DataFrame({'id': test_df_model.id, 'predicted': predictions_values})\n",
    "roberta_results.to_csv(\"roberta_results.csv\")\n",
    "\n",
    "# Store the results for comparison\n",
    "score = round(accuracy_score(test_df_model.labels, predictions_values),2)\n",
    "model_name = 'roberta_comment_only_without_cleaning'\n",
    "\n",
    "# Create a table with the final results and print the results\n",
    "roberta_results_table = pd.DataFrame([[model_name, score, round(end_time - start_time,0)]], columns = ['Model', 'Accuracy', 'Execution_Time_Seconds'])\n",
    "roberta_results_table.to_csv(\"roberta_results_table.csv\")\n",
    "roberta_results_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
